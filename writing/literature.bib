%---DATASET-------------------------------------------------------------------
% Describes the dataset that I am using:
@inproceedings{mensink14icmr,
  author = {Thomas Mensink and Jan van Gemert},
  title = {The Rijksmuseum Challenge: Museum-Centered Visual Recognition},
  booktitle = {ACM International Conference on Multimedia Retrieval (ICMR)},
  year = {2014}
}

%---TRANSFER-LEARNING---------------------------------------------------------
% PHD Thesis of Sabatelli:
@phdthesis{sabatelli2022contributions,
  title={Contributions to Deep Transfer Learning: from Supervised to Reinforcement Learning},
  author={Sabatelli, Matthia},
  year={2022},
  school={Universit{\'e} de Li{\`e}ge,​ Li{\`e}ge,​​ Belgique}
}

% The paper by Sabatelli that I will `replicate':
@inproceedings{sabatelli2018deep,
  title={Deep transfer learning for art classification problems},
  author={Sabatelli, Matthia and Kestemont, Mike and Daelemans, Walter and Geurts, Pierre},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV) Workshops},
  year={2018}
}

% Paper from long ago that found off-the-shelf performance of CNN was better
% than from-scratch performance of non-CNN models:
@inproceedings{sharif2014cnn,
  title={CNN features off-the-shelf: an astounding baseline for recognition},
  author={Sharif Razavian, Ali and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={806--813},
  year={2014}
}

% Paper that did lots of qualitative experiments w.r.t. CNNs transfer learning
% abilities:
@inproceedings{NIPS2014_375c7134,
 author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 publisher = {Curran Associates, Inc.},
 title = {How transferable are features in deep neural networks?},
 url = {https://proceedings.neurips.cc/paper/2014/file/375c71349b295fbe2dcdca9206f20a06-Paper.pdf},
 volume = {27},
 year = {2014}
}

%---VITS----------------------------------------------------------------------
% Paper that introduced Transformers:
@inproceedings{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

% Paper that introduced ViTs:
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

%---CNNS----------------------------------------------------------------------
% Paper that modern CNNs are attributed to
@inproceedings{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  booktitle={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  year={1998},
}

% AlexNet paper: start of CNN dominance
@inproceedings{krizhevsky2012imagened,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 volume = {25},
 year = {2012}
}

%---TRANSFER-LEARNING-WITH-VITS-----------------------------------------------
% Most interesting paper in the category:
@article{matsoukas2021time,
  title={Is it time to replace cnns with transformers for medical images?},
  author={Matsoukas, Christos and Haslum, Johan Fredin and S{\"o}derberg, Magnus and Smith, Kevin},
  journal={arXiv preprint arXiv:2108.09038},
  year={2021}
}

% Says interesting stuff about off-the-shelf performance of ViTs
@inproceedings{zhou2021convnets,
  title={ConvNets vs. Transformers: Whose Visual Representations are More Transferable?},
  author={Zhou, Hong-Yu and Lu, Chixiang and Yang, Sibei and Yu, Yizhou},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2230--2238},
  year={2021}
}

% This one did much qualitative analysis on ViTs
@inproceedings{raghu2021visio,
 author = {Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {12116--12128},
 publisher = {Curran Associates, Inc.},
 title = {Do Vision Transformers See Like Convolutional Neural Networks?},
 url = {https://proceedings.neurips.cc/paper/2021/file/652cf38361a209088302ba2b8b7f51e0-Paper.pdf},
 volume = {34},
 year = {2021}
}
