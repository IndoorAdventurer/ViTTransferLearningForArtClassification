\section{Introduction}
In the field of Computer Vision (CV), Convolutional Neural Networks (CNNs) have played an important role since the introduction of AlexNet, roughly a decade ago [BRON]. Recently, however, a new type of neural network architecture, called Vision Transformer (ViT), has gained state of the art performance on common learning benchmarks, including the famous ImageNet dataset [BRON/VOETNOOT].

Exciting as this may be, a plain ViT is not likely to become useful in circumstances with limited training data and/or only consumer-grade hardware available for learning. This is due to intrinsic limitations within the ViT architecture, that will be elaborated on below [subsectie]. The current paper investigates whether utilizing Transfer Learning (TL) capabilities of ViTs can help overcome these limitations, and if this allows ViTs to become the preferred architecture in the aforementioned circumstances as well.

This introduction section will first give high level descriptions of CNNs and ViTs, and how they compare to one another. What follows, is an explanation of TL, and why it might help ViTs in circumstances with limited data/compute available. Finally, background information on the topic of TL using ViTs is given, and a research question is proposed.

\subsection{Convolutional Neural Networks}
TODO
% First type of reduction in number of weights (compared to MLP) is that it only looks at surrounding pixels, instead of all
% Second type of reduction is that it re-uses the same weights for all pixels

\subsection{Vision Transformers}
TODO
% While a CNN is restricted to only incorporate information from its surrounding pixels in a subsequent layer, a ViT 

\paragraph{A limitation of Vision Transformers}
TODO

% CNNs have image specific inductive bias: the architecture itself is tailored to 2D images, and as such has structural information about how images work built-in. This is not the case for ViTs, which lack an image specific inductive bias, which makes them very data hungry.

\subsection{Transfer Learning}
TODO

\subsection{The current study}
TODO
