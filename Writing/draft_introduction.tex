\section{Introduction}
In the field of Computer Vision (CV), Convolutional Neural Networks (CNNs) have played an important role for a long time [BRON]. Recently, however, a new type of neural network architecture, called the Vision Transformer (ViT), has gained state of the art performance on common learning benchmarks, including the ImageNet dataset [BRON].

Exciting as this may be, a plain ViT is not likely to become useful in circumstances with limited training data and/or only consumer-grade hardware available for learning. This is due to intrinsic limitations within the ViT architecture, that will be elaborated on below [subsectie]. The current paper investigates whether utilizing Transfer Learning (TL) capabilities of ViTs can help overcome these limitations, and if they allow ViTs to become the preferred architecture in the aforementioned circumstances as well.

This introduction section will first give high level descriptions of CNNs and ViTs, and how they compare to one another. What follows, is an explanation of TL, and why it might help ViTs in circumstances with limited data/compute available. Finally, a research question is proposed.

\subsection{Convolutional Neural Networks}
TODO

\subsection{Vision Transformers}
TODO

\paragraph{A limitation of Vision Transformers}
TODO

\subsection{Transfer Learning}
TODO


