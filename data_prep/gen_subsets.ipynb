{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify location of csv superset:\n",
    "csv_file = \"/home/vincent/Documenten/BachelorsProject/GitHub_Repo/data_prep/subset_data.csv\"\n",
    "\n",
    "# Target name for dataset:\n",
    "datasetName = \"fullsize\"\n",
    "\n",
    "# Specify what fraction (<= 1) of the superset to use for the subsets:\n",
    "frac = 0.1\n",
    "assert frac > 0 and frac <= 1, \"frac must be between 0 and 1!\"\n",
    "\n",
    "# Specify what portions are used for the training, validation and testing set:\n",
    "split = {\n",
    "    \"train\": 0.8,   # You can specify as many subsets as you like!\n",
    "    \"val\"  : 0.1,   # Just make sure they add up to 1\n",
    "    \"test\" : 0.1\n",
    "}\n",
    "assert sum(split.values()) == 1 and \\\n",
    "    not any([x < 0 for x in split.values()]), \\\n",
    "    \"splits must sum to 1 and all be positive!\"\n",
    "\n",
    "# Getting the dataframe:\n",
    "superset = pd.read_csv(csv_file, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubsets(fracs, superset: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    If fracs is float, returns sample of 'superset' that is 'frac' times the size\n",
    "    If fracs is a dictionary with floats as values, returns mutually exclusive subsets with\n",
    "        the floats being the fraction of the superset per subset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert all inputs to dicts\n",
    "    fracs = fracs if isinstance(fracs, dict) else {\"whole\": fracs}\n",
    "    \n",
    "    # Create empty dataframes for each key\n",
    "    subsets = {key: pd.DataFrame(columns=superset.columns, index=None) for key in fracs}\n",
    "\n",
    "    # Iterate over all materials to make random n-way split for each\n",
    "    for material in superset[\"material\"].unique():\n",
    "        # Random permutation of df containing all instances of material:\n",
    "        tmpDf = superset[superset[\"material\"] == material].sample(frac=1.0)\n",
    "        \n",
    "        # Splitting it up into ranges df[0:x], df[x:y], df[y:z], etc\n",
    "        fracSum = 0.0\n",
    "        end = 0\n",
    "        for key in fracs:\n",
    "            start = end\n",
    "            fracSum += fracs[key]\n",
    "            end = int(fracSum * len(tmpDf))\n",
    "            if start == end:\n",
    "                print(\"WARNING: No instances of {material} in {key} set\")\n",
    "            subsets[key] = pd.concat([subsets[key], tmpDf.iloc[start:end, :]])\n",
    "            start = end\n",
    "    \n",
    "    # Each subset should randomly be permuted, and indeces should be reset:\n",
    "    for key in subsets:\n",
    "        subsets[key] = subsets[key].sample(frac=1.0)\n",
    "\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a fraction of the superset:\n",
    "subset = getSubsets(frac, superset)[\"whole\"]\n",
    "\n",
    "# Getting 3 splits of the subset:\n",
    "subsets = getSubsets(split, subset)\n",
    "\n",
    "# Saving each to a csv-file:\n",
    "for ss in subsets:\n",
    "    subsets[ss].to_csv(f\"{datasetName}-{ss}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
